# TODO - AmÃ©liorations du RÃ©seau de Neurones

## âœ… ComplÃ©tÃ©

- [x] ImplÃ©mentation des fonctions d'activation configurables
- [x] Documentation dÃ©taillÃ©e de toutes les activations
- [x] Enum `Activation` avec 15 fonctions

## ğŸ”„ Ã€ Ã‰tudier : Loss Functions (Fonctions de Perte)

### Concept de Base

La **loss function** (fonction de perte/coÃ»t) mesure **Ã  quel point le rÃ©seau se trompe** dans ses prÃ©dictions.

**Objectif** : Minimiser l'erreur entre la prÃ©diction et la valeur rÃ©elle.

```
Loss = DiffÃ©rence(PrÃ©diction, Valeur_RÃ©elle)
```

Plus la loss est **petite** â†’ meilleure prÃ©diction  
Plus la loss est **grande** â†’ pire prÃ©diction

---

### Actuellement dans le Code

```rust
let output_errors = target - &final_output;  // Erreur brute
let output_delta = &output_errors * &self.output_activation.derivative(&final_output);
```

**Loss actuelle :** MSE (Mean Squared Error) implicite

$$\text{MSE} = \frac{1}{n}\sum(y_{rÃ©el} - y_{prÃ©dit})^2$$

---

### Principales Loss Functions

#### 1. MSE (Mean Squared Error)
**Formule :** $\text{MSE} = \frac{1}{n}\sum(y - \hat{y})^2$

**Usage :** RÃ©gression (prÃ©dire des valeurs continues)

**Avantages :**
- âœ… PÃ©nalise fortement les grandes erreurs
- âœ… DiffÃ©rentiable partout

**InconvÃ©nients :**
- âŒ Pas optimal pour classification
- âŒ Gradient qui disparaÃ®t avec Sigmoid

**Exemple :**
```
PrÃ©diction: 2.5, RÃ©el: 3.0
Loss = (3.0 - 2.5)Â² = 0.25
```

---

#### 2. MAE (Mean Absolute Error)
**Formule :** $\text{MAE} = \frac{1}{n}\sum|y - \hat{y}|$

**Usage :** RÃ©gression (moins sensible aux outliers)

**Avantages :**
- âœ… Robuste aux outliers
- âœ… InterprÃ©tation intuitive

**Exemple :**
```
PrÃ©diction: 2.5, RÃ©el: 3.0
Loss = |3.0 - 2.5| = 0.5
```

---

#### 3. Binary Cross-Entropy (Log Loss)
**Formule :** $\text{BCE} = -\frac{1}{n}\sum[y\log(\hat{y}) + (1-y)\log(1-\hat{y})]$

**Usage :** Classification binaire (avec Sigmoid)

**Avantages :**
- âœ… InterprÃ©tation probabiliste
- âœ… Gradient plus stable que MSE pour classification
- âœ… Convergence plus rapide

**InconvÃ©nients :**
- âŒ NÃ©cessite prÃ©dictions dans [0, 1]
- âŒ Instable si prÃ©diction = 0 ou 1 (log(0))

**Exemple :**
```
PrÃ©diction: 0.9, RÃ©el: 1 (chien)
Loss = -[1Ã—log(0.9) + 0Ã—log(0.1)] = 0.105

PrÃ©diction: 0.1, RÃ©el: 1 (chien)
Loss = -[1Ã—log(0.1) + 0Ã—log(0.9)] = 2.303  // Grosse erreur!
```

**ImplÃ©mentation Rust :**
```rust
fn binary_cross_entropy(prediction: f64, target: f64) -> f64 {
    let epsilon = 1e-15; // Ã‰viter log(0)
    let p = prediction.max(epsilon).min(1.0 - epsilon);
    -(target * p.ln() + (1.0 - target) * (1.0 - p).ln())
}
```

---

#### 4. Categorical Cross-Entropy
**Formule :** $\text{CCE} = -\sum y_i \log(\hat{y}_i)$

**Usage :** Classification multi-classes (avec Softmax)

**Avantages :**
- âœ… Standard pour multi-classes
- âœ… InterprÃ©tation probabiliste claire

**Exemple :**
```
Classes: [Chat, Chien, Oiseau]
RÃ©el:    [1,    0,     0]      // C'est un chat
PrÃ©dit:  [0.7,  0.2,   0.1]
Loss = -(1Ã—log(0.7) + 0Ã—log(0.2) + 0Ã—log(0.1)) = 0.357
```

**ImplÃ©mentation Rust :**
```rust
fn categorical_cross_entropy(predictions: &Array1<f64>, targets: &Array1<f64>) -> f64 {
    let epsilon = 1e-15;
    -targets.iter()
        .zip(predictions.iter())
        .map(|(t, p)| t * (p.max(epsilon)).ln())
        .sum::<f64>()
}
```

---

#### 5. Huber Loss
**Formule :** 
$$\text{Huber} = \begin{cases} \frac{1}{2}(y - \hat{y})^2 & \text{si } |y - \hat{y}| \leq \delta \\ \delta(|y - \hat{y}| - \frac{1}{2}\delta) & \text{sinon} \end{cases}$$

**Usage :** RÃ©gression robuste aux outliers

**Avantages :**
- âœ… Combine MSE (petites erreurs) et MAE (grandes erreurs)
- âœ… Moins sensible aux outliers que MSE

---

### Relation avec le Training

**Cycle d'apprentissage :**

```
1. Forward pass â†’ PrÃ©diction
2. Calcul de la Loss â†’ Mesurer l'erreur
3. Backpropagation â†’ Calculer les gradients
4. Update des poids â†’ RÃ©duire la Loss
```

---

### Guide de SÃ©lection des Loss Functions

| **TÃ¢che** | **Activation Sortie** | **Loss Function RecommandÃ©e** |
|-----------|----------------------|-------------------------------|
| RÃ©gression | Linear | **MSE** (dÃ©faut) |
| RÃ©gression robuste | Linear | **MAE** ou **Huber** |
| Classification binaire | Sigmoid | **Binary Cross-Entropy** |
| Classification multi-classes | Softmax | **Categorical Cross-Entropy** |
| DÃ©tection d'objets | Variable | IoU Loss, Focal Loss |
| Segmentation | Softmax | Dice Loss, Focal Loss |

---

### Pourquoi Changer de Loss pour XOR ?

**ProblÃ¨me actuel :** MSE + Sigmoid pour classification binaire

**MSE pour classification :**
- âŒ Gradient qui disparaÃ®t quand proche de 0 ou 1
- âŒ Pas d'interprÃ©tation probabiliste
- âŒ Convergence plus lente

**Binary Cross-Entropy pour classification :**
- âœ… Gradient plus stable
- âœ… Converge plus vite
- âœ… InterprÃ©tation comme probabilitÃ©

---

### Visualisation de la Convergence

```
Haute Loss â”â”â”â”â”â”â”â”â”â”“
                    â”ƒ    DÃ©but
                    â”ƒ      â†“
                    â”ƒ      â€¢
                    â”ƒ     â•±
                    â”ƒ    â•±
                    â”ƒ   â•±     Training
                    â”ƒ  â•±      â†“
                    â”ƒ â•±
Basse Loss â”â”â”â”â”â”â”â”â”â”ƒâ•±________â€¢ Convergence
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
                         Epochs
```

**Objectif du training** : Descendre cette courbe le plus vite possible.

---

## ğŸ“ Prochaines Ã‰tapes

### Ã€ ImplÃ©menter

- [ ] Ajouter un enum `LossFunction` similaire Ã  `Activation`
- [ ] ImplÃ©menter Binary Cross-Entropy
- [ ] ImplÃ©menter Categorical Cross-Entropy
- [ ] ImplÃ©menter MAE
- [ ] ImplÃ©menter Huber Loss
- [ ] Permettre de choisir la loss dans `Network::new()`
- [ ] Modifier `train()` pour utiliser la loss choisie
- [ ] Ajouter une mÃ©thode `evaluate()` pour calculer la loss sans update

### Structure ProposÃ©e

```rust
pub enum LossFunction {
    MSE,
    MAE,
    BinaryCrossEntropy,
    CategoricalCrossEntropy,
    Huber,
}

impl LossFunction {
    pub fn compute(&self, predictions: &Array1<f64>, targets: &Array1<f64>) -> f64 {
        // Calcul de la loss
    }
    
    pub fn derivative(&self, predictions: &Array1<f64>, targets: &Array1<f64>) -> Array1<f64> {
        // Gradient pour backprop
    }
}

pub struct Network {
    // ... existing fields
    loss_function: LossFunction,
}
```

### Tests Ã  Effectuer

- [ ] Comparer MSE vs BCE sur XOR
- [ ] Mesurer la vitesse de convergence
- [ ] Tester sur problÃ¨mes multi-classes
- [ ] Valider les gradients numÃ©riquement

---

## ğŸ“š Ressources

- **Cross-Entropy :** [Understanding Cross-Entropy](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)
- **Loss Functions :** [PyTorch Loss Functions](https://pytorch.org/docs/stable/nn.html#loss-functions)
- **Comparaison :** [When to use which loss?](https://machinelearningmastery.com/loss-functions-for-neural-networks/)

---

## ğŸ”— Liens Internes

- Voir [readme.md](readme.md) pour la documentation des activations
- Voir [src/network.rs](src/network.rs) pour l'implÃ©mentation actuelle
